{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-15T18:16:40.023933Z",
     "start_time": "2025-12-15T18:16:38.880974Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from games.tictactoe import TicTacToe\n",
    "from games.connectfour import ConnectFour\n",
    "from models.mcts import MCTS, MCTSParallel\n",
    "from models.resnet import ResNet\n",
    "from models.deepzero import DeepZero, DeepZeroParallel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# tictactoe game",
   "id": "966d13a051eb6121"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:59:17.846042Z",
     "start_time": "2025-12-15T13:59:17.844486Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a7b794537a1732c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T14:05:50.351673Z",
     "start_time": "2025-12-15T14:05:45.434823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game = TicTacToe()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = ResNet(game, 4, 32, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "player = 1\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 100,\n",
    "    'num_iterations': 3,\n",
    "    'num_parallel_games': 100,\n",
    "    'batch_size': 16,\n",
    "    'num_selfplay_iterations': 350,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 1\n",
    "}\n",
    "\n",
    "deepzero = DeepZeroParallel(model, optimizer, game, args)\n",
    "deepzero.learn()\n"
   ],
   "id": "83e6c74a1acb2f75",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     10\u001B[39m args = {\n\u001B[32m     11\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mC\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m2\u001B[39m,\n\u001B[32m     12\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mnum_search\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m100\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     20\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mdirichlet_alpha\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m1\u001B[39m\n\u001B[32m     21\u001B[39m }\n\u001B[32m     23\u001B[39m deepzero = DeepZeroParallel(model, optimizer, game, args)\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[43mdeepzero\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/deepzero.py:177\u001B[39m, in \u001B[36mDeepZeroParallel.learn\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    175\u001B[39m \u001B[38;5;28mself\u001B[39m.model.eval()\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m selfPlay_iteration \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;28mself\u001B[39m.args[\u001B[33m'\u001B[39m\u001B[33mnum_selfplay_iterations\u001B[39m\u001B[33m'\u001B[39m] // \u001B[38;5;28mself\u001B[39m.args[\u001B[33m'\u001B[39m\u001B[33mnum_parallel_games\u001B[39m\u001B[33m'\u001B[39m]):\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m     memory += \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mselfPlay\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[38;5;28mself\u001B[39m.model.train()\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;28mself\u001B[39m.args[\u001B[33m'\u001B[39m\u001B[33mnum_epochs\u001B[39m\u001B[33m'\u001B[39m]):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/deepzero.py:113\u001B[39m, in \u001B[36mDeepZeroParallel.selfPlay\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    110\u001B[39m states = np.stack([spg.state \u001B[38;5;28;01mfor\u001B[39;00m spg \u001B[38;5;129;01min\u001B[39;00m spGames])\n\u001B[32m    111\u001B[39m neutral_states = \u001B[38;5;28mself\u001B[39m.game.change_perspective(states, player)\n\u001B[32m--> \u001B[39m\u001B[32m113\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmcts\u001B[49m\u001B[43m.\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneutral_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspGames\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(spGames))[::-\u001B[32m1\u001B[39m]:\n\u001B[32m    116\u001B[39m     spg = spGames[i]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/mcts.py:148\u001B[39m, in \u001B[36mMCTSParallel.search\u001B[39m\u001B[34m(self, states, spGames)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m node.is_fully_expanded():\n\u001B[32m    146\u001B[39m     node = node.select()\n\u001B[32m--> \u001B[39m\u001B[32m148\u001B[39m value, is_terminal = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgame\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_value_and_terminated\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m.\u001B[49m\u001B[43maction_taken\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    149\u001B[39m value = \u001B[38;5;28mself\u001B[39m.game.get_opponent_value(value)\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_terminal:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/games/tictactoe.py:41\u001B[39m, in \u001B[36mTicTacToe.get_value_and_terminated\u001B[39m\u001B[34m(self, state, action)\u001B[39m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_value_and_terminated\u001B[39m(\u001B[38;5;28mself\u001B[39m, state, action):\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcheck_win\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m     42\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[32m1\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     43\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m np.sum(\u001B[38;5;28mself\u001B[39m.get_valid_moves(state)) == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/games/tictactoe.py:36\u001B[39m, in \u001B[36mTicTacToe.check_win\u001B[39m\u001B[34m(self, state, action)\u001B[39m\n\u001B[32m     30\u001B[39m column = action % \u001B[38;5;28mself\u001B[39m.column_count\n\u001B[32m     31\u001B[39m player = state[row, column]\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[32m     34\u001B[39m         np.sum(state[row, :]) == player * \u001B[38;5;28mself\u001B[39m.column_count\n\u001B[32m     35\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m np.sum(state[:, column]) == player * \u001B[38;5;28mself\u001B[39m.row_count\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m np.sum(\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdiag\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m) == player * \u001B[38;5;28mself\u001B[39m.row_count\n\u001B[32m     37\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m np.sum(np.diag(np.flip(state, axis=\u001B[32m0\u001B[39m))) == player * \u001B[38;5;28mself\u001B[39m.row_count\n\u001B[32m     38\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/numpy/lib/_twodim_base_impl.py:254\u001B[39m, in \u001B[36m_diag_dispatcher\u001B[39m\u001B[34m(v, k)\u001B[39m\n\u001B[32m    248\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m m\n\u001B[32m    251\u001B[39m _eye_with_like = array_function_dispatch()(eye)\n\u001B[32m--> \u001B[39m\u001B[32m254\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_diag_dispatcher\u001B[39m(v, k=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    255\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (v,)\n\u001B[32m    258\u001B[39m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_diag_dispatcher)\n\u001B[32m    259\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdiag\u001B[39m(v, k=\u001B[32m0\u001B[39m):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:52:08.204746Z",
     "start_time": "2025-12-15T13:51:34.838489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game = TicTacToe()\n",
    "player = -1\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 100,\n",
    "    'num_iterations': 3,\n",
    "    'num_parallel_games': 100,\n",
    "    'batch_size': 16,\n",
    "    'num_selfplay_iterations': 350,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "\n",
    "model = ResNet(game, 4, 32, device=device)\n",
    "model.load_state_dict(torch.load(\"weights/model_2_TicTacToe.pt\", map_location=device))\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        print(\"val_movies\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}: \"))\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not val\")\n",
    "            continue\n",
    "    else:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        mcts_probs, net_win_value = mcts.search(neutral_state)\n",
    "        print(\"expected win rate\", net_win_value)\n",
    "        mcts_probs = mcts_probs * valid_moves  # Mask invalid moves to zero\n",
    "        action = np.argmax(mcts_probs)\n",
    "        # Optional: Add a check for no valid moves, though this should not occur in a proper game state\n",
    "        if valid_moves[action] == 0:\n",
    "            raise ValueError(\"No valid moves available; game state may be invalid.\")\n",
    "\n",
    "    state = game.get_next_state(state, action, player)\n",
    "    value, is_terminate = game.get_value_and_terminated(state, action)\n",
    "    if is_terminate:\n",
    "        if value == 1:\n",
    "            print(player, \"win\")\n",
    "        else:\n",
    "            print(player, \"lose\")\n",
    "        break\n",
    "    player = game.get_opponent(player)"
   ],
   "id": "2e7f7b9aa1788d1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "expected win rate -0.3342079520225525\n",
      "[[ 0. -1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "val_movies [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "[[ 0. -1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "expected win rate 0.16230599582195282\n",
      "[[ 0. -1. -1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "val_movies [0, 3, 4, 5, 6, 7]\n",
      "[[ 1. -1. -1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "expected win rate 0.49623584747314453\n",
      "[[ 1. -1. -1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "val_movies [3, 5, 6, 7]\n",
      "[[ 1. -1. -1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  1.  1.]]\n",
      "expected win rate 0.4345284402370453\n",
      "-1 win\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:54:11.613045Z",
     "start_time": "2025-12-15T13:52:59.303743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game = ConnectFour()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = ResNet(game, 9, 64, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "player = 1\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 600,\n",
    "    'num_iterations': 8,\n",
    "    'batch_size': 64,\n",
    "    'num_selfplay_iterations': 500,\n",
    "    'num_parallel_games': 100,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "deepzero = DeepZeroParallel(model, optimizer, game, args)\n",
    "deepzero.learn()\n"
   ],
   "id": "269bc8b9c80750d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [01:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     10\u001B[39m args = {\n\u001B[32m     11\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mC\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m2\u001B[39m,\n\u001B[32m     12\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mnum_search\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m600\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     20\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mdirichlet_alpha\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m0.3\u001B[39m\n\u001B[32m     21\u001B[39m }\n\u001B[32m     23\u001B[39m deepzero = DeepZeroParallel(model, optimizer, game, args)\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[43mdeepzero\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/deepzero.py:177\u001B[39m, in \u001B[36mDeepZeroParallel.learn\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    175\u001B[39m \u001B[38;5;28mself\u001B[39m.model.eval()\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m selfPlay_iteration \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;28mself\u001B[39m.args[\u001B[33m'\u001B[39m\u001B[33mnum_selfplay_iterations\u001B[39m\u001B[33m'\u001B[39m] // \u001B[38;5;28mself\u001B[39m.args[\u001B[33m'\u001B[39m\u001B[33mnum_parallel_games\u001B[39m\u001B[33m'\u001B[39m]):\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m     memory += \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mselfPlay\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[38;5;28mself\u001B[39m.model.train()\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;28mself\u001B[39m.args[\u001B[33m'\u001B[39m\u001B[33mnum_epochs\u001B[39m\u001B[33m'\u001B[39m]):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/deepzero.py:113\u001B[39m, in \u001B[36mDeepZeroParallel.selfPlay\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    110\u001B[39m states = np.stack([spg.state \u001B[38;5;28;01mfor\u001B[39;00m spg \u001B[38;5;129;01min\u001B[39;00m spGames])\n\u001B[32m    111\u001B[39m neutral_states = \u001B[38;5;28mself\u001B[39m.game.change_perspective(states, player)\n\u001B[32m--> \u001B[39m\u001B[32m113\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmcts\u001B[49m\u001B[43m.\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneutral_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspGames\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(spGames))[::-\u001B[32m1\u001B[39m]:\n\u001B[32m    116\u001B[39m     spg = spGames[i]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/mcts.py:177\u001B[39m, in \u001B[36mMCTSParallel.search\u001B[39m\u001B[34m(self, states, spGames)\u001B[39m\n\u001B[32m    174\u001B[39m spg_policy *= valid_moves\n\u001B[32m    175\u001B[39m spg_policy /= np.sum(spg_policy)\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m \u001B[43mnode\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexpand\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspg_policy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m node.backpropagate(spg_value)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/mcts.py:46\u001B[39m, in \u001B[36mNode.expand\u001B[39m\u001B[34m(self, policy)\u001B[39m\n\u001B[32m     44\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m prob > \u001B[32m0\u001B[39m:\n\u001B[32m     45\u001B[39m     child_state = \u001B[38;5;28mself\u001B[39m.state.copy()\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m     child_state = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgame\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_next_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchild_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     47\u001B[39m     child_state = \u001B[38;5;28mself\u001B[39m.game.change_perspective(child_state, player=-\u001B[32m1\u001B[39m)\n\u001B[32m     49\u001B[39m     child = Node(\u001B[38;5;28mself\u001B[39m.game, \u001B[38;5;28mself\u001B[39m.args, child_state, \u001B[38;5;28mself\u001B[39m, action, prob)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/games/connectfour.py:17\u001B[39m, in \u001B[36mConnectFour.get_next_state\u001B[39m\u001B[34m(self, state, action, player)\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_next_state\u001B[39m(\u001B[38;5;28mself\u001B[39m, state, action, player):\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     row = np.max(\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[32m     18\u001B[39m     state[row, action] = player\n\u001B[32m     19\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m state\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T18:36:32.140929Z",
     "start_time": "2025-12-15T18:36:32.083127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game = ConnectFour()\n",
    "player = -1\n",
    "device = torch.device(\"cpu\")\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 500,\n",
    "    'num_iterations': 10,\n",
    "    'batch_size': 64,\n",
    "    'num_selfplay_iterations': 500,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "model = ResNet(game, 9, 128, device=device)\n",
    "model.load_state_dict(torch.load(\"weights/model_4_ConnectFour.pt\", map_location=device))\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        print(\"val_movies\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}: \"))\n",
    "\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not val\")\n",
    "            continue\n",
    "    else:\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        mcts_probs, net_win_value = mcts.search(neutral_state)\n",
    "        print(\"expected win rate\", net_win_value)\n",
    "        action = np.argmax(mcts_probs)\n",
    "\n",
    "    state = game.get_next_state(state, action, player)\n",
    "\n",
    "    value, is_terminate = game.get_value_and_terminated(state, action)\n",
    "\n",
    "    if is_terminate:\n",
    "        if value == 1:\n",
    "            print(player, \"win\")\n",
    "        else:\n",
    "             print(player, \"lose\")\n",
    "        break\n",
    "\n",
    "    player = game.get_opponent(player)"
   ],
   "id": "529975a467b87707",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConnectFour' object has no attribute 'shape_obs'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m      3\u001B[39m device = torch.device(\u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      4\u001B[39m args = {\n\u001B[32m      5\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mC\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m2\u001B[39m,\n\u001B[32m      6\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mnum_search\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m500\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     13\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mdirichlet_alpha\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m0.3\u001B[39m\n\u001B[32m     14\u001B[39m }\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m model = \u001B[43mResNet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgame\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m9\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m model.load_state_dict(torch.load(\u001B[33m\"\u001B[39m\u001B[33mweights/model_4_ConnectFour.pt\u001B[39m\u001B[33m\"\u001B[39m, map_location=device))\n\u001B[32m     17\u001B[39m model.eval()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/resnet.py:12\u001B[39m, in \u001B[36mResNet.__init__\u001B[39m\u001B[34m(self, game, num_resBlock, num_hidden, device)\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m()\n\u001B[32m      9\u001B[39m \u001B[38;5;28mself\u001B[39m.device = device\n\u001B[32m     11\u001B[39m \u001B[38;5;28mself\u001B[39m.startBlock = nn.Sequential(\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m     nn.Conv2d(\u001B[43mgame\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshape_obs\u001B[49m, num_hidden, kernel_size=\u001B[32m3\u001B[39m, padding=\u001B[32m1\u001B[39m),\n\u001B[32m     13\u001B[39m     nn.BatchNorm2d(num_hidden),\n\u001B[32m     14\u001B[39m     nn.ReLU(),\n\u001B[32m     15\u001B[39m )\n\u001B[32m     17\u001B[39m \u001B[38;5;28mself\u001B[39m.backBone = nn.ModuleList(\n\u001B[32m     18\u001B[39m     [ResBlock(num_hidden) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_resBlock)]\n\u001B[32m     19\u001B[39m )\n\u001B[32m     21\u001B[39m \u001B[38;5;28mself\u001B[39m.policyHead = nn.Sequential(\n\u001B[32m     22\u001B[39m     nn.Conv2d(num_hidden, \u001B[32m32\u001B[39m, kernel_size=\u001B[32m3\u001B[39m, padding=\u001B[32m1\u001B[39m),\n\u001B[32m     23\u001B[39m     nn.BatchNorm2d(\u001B[32m32\u001B[39m),\n\u001B[32m   (...)\u001B[39m\u001B[32m     26\u001B[39m     nn.Linear(\u001B[32m32\u001B[39m * game.row_count * game.column_count, game.action_size),\n\u001B[32m     27\u001B[39m )\n",
      "\u001B[31mAttributeError\u001B[39m: 'ConnectFour' object has no attribute 'shape_obs'"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T19:29:54.962698Z",
     "start_time": "2025-12-15T19:29:54.939974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Checkers:\n",
    "    def __init__(self):\n",
    "        self.row_count = 8\n",
    "        self.column_count = 8\n",
    "        self.shape_obs = 5\n",
    "        # Действие кодируется как: from_pos * 64 + to_pos\n",
    "        # from_pos = row * 8 + col, to_pos = row * 8 + col\n",
    "        self.action_size = 64 * 64  # 4096 возможных действий\n",
    "        # Фигуры: 1 = шашка текущего игрока, 2 = дамка текущего игрока\n",
    "        #        -1 = шашка противника, -2 = дамка противника\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Checkers\"\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        \"\"\"Возвращает начальное состояние доски 8x8\"\"\"\n",
    "        state = np.zeros((self.row_count, self.column_count), dtype=np.int8)\n",
    "\n",
    "        # Расставляем шашки только на тёмных клетках (row + col) % 2 == 1\n",
    "        for row in range(self.row_count):\n",
    "            for col in range(self.column_count):\n",
    "                if (row + col) % 2 == 1:\n",
    "                    if row < 3:\n",
    "                        state[row, col] = -1  # Шашки противника (вверху)\n",
    "                    elif row > 4:\n",
    "                        state[row, col] = 1   # Шашки игрока (внизу)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def flip_action(self, action):\n",
    "        \"\"\"Переворачивает action после change_perspective\"\"\"\n",
    "        from_pos = action // 64\n",
    "        to_pos = action % 64\n",
    "\n",
    "        from_row, from_col = from_pos // 8, from_pos % 8\n",
    "        to_row, to_col = to_pos // 8, to_pos % 8\n",
    "\n",
    "        new_from_row = 7 - from_row\n",
    "        new_to_row = 7 - to_row\n",
    "\n",
    "        new_from_pos = new_from_row * 8 + from_col\n",
    "        new_to_pos = new_to_row * 8 + to_col\n",
    "\n",
    "        return new_from_pos * 64 + new_to_pos\n",
    "\n",
    "    def get_next_state(self, state, action, player):\n",
    "        \"\"\"\n",
    "        Применяет действие к состоянию и возвращает новое состояние.\n",
    "        Состояние должно быть с перспективы player (после change_perspective).\n",
    "        \"\"\"\n",
    "        state = state.copy()\n",
    "\n",
    "        from_pos = action // 64\n",
    "        to_pos = action % 64\n",
    "\n",
    "        from_row, from_col = from_pos // 8, from_pos % 8\n",
    "        to_row, to_col = to_pos // 8, to_pos % 8\n",
    "\n",
    "        piece = state[from_row, from_col]\n",
    "        state[from_row, from_col] = 0\n",
    "\n",
    "        # Проверяем взятие (прыжок через 2 клетки)\n",
    "        if abs(to_row - from_row) == 2:\n",
    "            captured_row = (from_row + to_row) // 2\n",
    "            captured_col = (from_col + to_col) // 2\n",
    "            state[captured_row, captured_col] = 0\n",
    "\n",
    "        # Превращение в дамку при достижении верхнего края (row == 0)\n",
    "        # Игрок 1 всегда двигается вверх\n",
    "        if piece == 1 and to_row == 0:\n",
    "            state[to_row, to_col] = 2  # Дамка\n",
    "        else:\n",
    "            state[to_row, to_col] = piece\n",
    "\n",
    "        return state\n",
    "\n",
    "    def get_valid_moves(self, state):\n",
    "        \"\"\"\n",
    "        Возвращает маску допустимых ходов размером action_size.\n",
    "        Если есть взятия - возвращает только взятия (взятие обязательно).\n",
    "        Предполагается что state с перспективы текущего игрока (player=1).\n",
    "        \"\"\"\n",
    "        valid_moves = np.zeros(self.action_size, dtype=np.uint8)\n",
    "        captures = []\n",
    "        regular_moves = []\n",
    "\n",
    "        for row in range(self.row_count):\n",
    "            for col in range(self.column_count):\n",
    "                piece = state[row, col]\n",
    "\n",
    "                # Ищем фигуры текущего игрока (1 = шашка, 2 = дамка)\n",
    "                if piece != 1 and piece != 2:\n",
    "                    continue\n",
    "\n",
    "                is_king = piece == 2\n",
    "\n",
    "                # Направления движения: шашка вверх, дамка в обе стороны\n",
    "                if is_king:\n",
    "                    directions = [(-1, -1), (-1, 1), (1, -1), (1, 1)]\n",
    "                else:\n",
    "                    directions = [(-1, -1), (-1, 1)]  # Только вверх\n",
    "\n",
    "                for dr, dc in directions:\n",
    "                    new_row, new_col = row + dr, col + dc\n",
    "\n",
    "                    if not self._is_valid_position(new_row, new_col):\n",
    "                        continue\n",
    "\n",
    "                    target = state[new_row, new_col]\n",
    "\n",
    "                    if target == 0:\n",
    "                        # Обычный ход\n",
    "                        from_pos = row * 8 + col\n",
    "                        to_pos = new_row * 8 + new_col\n",
    "                        action = from_pos * 64 + to_pos\n",
    "                        regular_moves.append(action)\n",
    "\n",
    "                    elif target == -1 or target == -2:\n",
    "                        # Возможное взятие (фигура противника)\n",
    "                        jump_row, jump_col = new_row + dr, new_col + dc\n",
    "                        if self._is_valid_position(jump_row, jump_col) and state[jump_row, jump_col] == 0:\n",
    "                            from_pos = row * 8 + col\n",
    "                            to_pos = jump_row * 8 + jump_col\n",
    "                            action = from_pos * 64 + to_pos\n",
    "                            captures.append(action)\n",
    "\n",
    "                # Для обычной шашки проверяем взятие назад\n",
    "                if not is_king:\n",
    "                    for dr, dc in [(1, -1), (1, 1)]:  # Назад\n",
    "                        new_row, new_col = row + dr, col + dc\n",
    "\n",
    "                        if not self._is_valid_position(new_row, new_col):\n",
    "                            continue\n",
    "\n",
    "                        target = state[new_row, new_col]\n",
    "\n",
    "                        if target == -1 or target == -2:\n",
    "                            jump_row, jump_col = new_row + dr, new_col + dc\n",
    "                            if self._is_valid_position(jump_row, jump_col) and state[jump_row, jump_col] == 0:\n",
    "                                from_pos = row * 8 + col\n",
    "                                to_pos = jump_row * 8 + jump_col\n",
    "                                action = from_pos * 64 + to_pos\n",
    "                                captures.append(action)\n",
    "\n",
    "        # Взятие обязательно\n",
    "        moves_to_use = captures if len(captures) > 0 else regular_moves\n",
    "\n",
    "        for action in moves_to_use:\n",
    "            valid_moves[action] = 1\n",
    "\n",
    "        return valid_moves\n",
    "\n",
    "    def check_win(self, state, action):\n",
    "        \"\"\"\n",
    "        Проверяет победу после хода.\n",
    "        Победа если у противника нет фигур или нет допустимых ходов.\n",
    "        \"\"\"\n",
    "        if action is None:\n",
    "            return False\n",
    "\n",
    "        # Проверяем, есть ли фигуры у противника\n",
    "        opponent_pieces = np.sum((state == -1) | (state == -2))\n",
    "        if opponent_pieces == 0:\n",
    "            return True\n",
    "\n",
    "        # Проверяем, есть ли допустимые ходы у противника\n",
    "        # Меняем перспективу и проверяем ходы\n",
    "        opponent_state = self.change_perspective(state, -1)\n",
    "        opponent_moves = self.get_valid_moves(opponent_state)\n",
    "        if np.sum(opponent_moves) == 0:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        \"\"\"\n",
    "        Возвращает (value, terminated).\n",
    "        value = 1 при победе текущего игрока, 0 при ничьей или продолжении.\n",
    "        \"\"\"\n",
    "        if self.check_win(state, action):\n",
    "            return 1, True\n",
    "\n",
    "        # Проверка на ничью (нет ходов у текущего игрока)\n",
    "        if np.sum(self.get_valid_moves(state)) == 0:\n",
    "            return 0, True\n",
    "\n",
    "        return 0, False\n",
    "\n",
    "    def get_opponent(self, player):\n",
    "        \"\"\"Возвращает противника\"\"\"\n",
    "        return -player\n",
    "\n",
    "    def get_opponent_value(self, value):\n",
    "        \"\"\"Возвращает значение с точки зрения противника\"\"\"\n",
    "        return -value\n",
    "\n",
    "    def change_perspective(self, state, player):\n",
    "        \"\"\"\n",
    "        Меняет перспективу доски для игрока.\n",
    "        После вызова текущий игрок всегда представлен как player=1.\n",
    "        Доска переворачивается и значения инвертируются.\n",
    "        \"\"\"\n",
    "        if player == -1:\n",
    "            # Переворачиваем доску и меняем знаки фигур\n",
    "            return np.flip(state, axis=0) * -1\n",
    "        return state.copy()\n",
    "\n",
    "    def get_encoded_state(self, state):\n",
    "        \"\"\"\n",
    "        Кодирует состояние для нейронной сети.\n",
    "        Возвращает 5 каналов:\n",
    "        - Шашки текущего игрока (1)\n",
    "        - Дамки текущего игрока (2)\n",
    "        - Шашки противника (-1)\n",
    "        - Дамки противника (-2)\n",
    "        - Пустые клетки (0)\n",
    "        \"\"\"\n",
    "        encoded_state = np.stack(\n",
    "            (\n",
    "                (state == 1).astype(np.float32),   # Мои шашки\n",
    "                (state == 2).astype(np.float32),   # Мои дамки\n",
    "                (state == -1).astype(np.float32),  # Шашки противника\n",
    "                (state == -2).astype(np.float32),  # Дамки противника\n",
    "                (state == 0).astype(np.float32)    # Пустые клетки\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if len(state.shape) == 3:\n",
    "            encoded_state = np.swapaxes(encoded_state, 0, 1)\n",
    "\n",
    "        return encoded_state\n",
    "\n",
    "    def _is_valid_position(self, row, col):\n",
    "        \"\"\"Проверяет, находится ли позиция в пределах доски\"\"\"\n",
    "        return 0 <= row < self.row_count and 0 <= col < self.column_count\n",
    "\n",
    "    def has_additional_captures(self, state, row, col):\n",
    "        \"\"\"Проверяет, есть ли дополнительные взятия для шашки после хода\"\"\"\n",
    "        piece = state[row, col]\n",
    "        if piece != 1 and piece != 2:\n",
    "            return False\n",
    "\n",
    "        # Все направления для взятия\n",
    "        directions = [(-1, -1), (-1, 1), (1, -1), (1, 1)]\n",
    "\n",
    "        for dr, dc in directions:\n",
    "            new_row, new_col = row + dr, col + dc\n",
    "\n",
    "            if not self._is_valid_position(new_row, new_col):\n",
    "                continue\n",
    "\n",
    "            target = state[new_row, new_col]\n",
    "            if target == -1 or target == -2:\n",
    "                jump_row, jump_col = new_row + dr, new_col + dc\n",
    "                if self._is_valid_position(jump_row, jump_col) and state[jump_row, jump_col] == 0:\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_captures_for_piece(self, state, row, col):\n",
    "        \"\"\"Возвращает список взятий для конкретной шашки\"\"\"\n",
    "        captures = []\n",
    "        piece = state[row, col]\n",
    "\n",
    "        if piece != 1 and piece != 2:\n",
    "            return captures\n",
    "\n",
    "        directions = [(-1, -1), (-1, 1), (1, -1), (1, 1)]\n",
    "\n",
    "        for dr, dc in directions:\n",
    "            new_row, new_col = row + dr, col + dc\n",
    "\n",
    "            if not self._is_valid_position(new_row, new_col):\n",
    "                continue\n",
    "\n",
    "            target = state[new_row, new_col]\n",
    "            if target == -1 or target == -2:\n",
    "                jump_row, jump_col = new_row + dr, new_col + dc\n",
    "                if self._is_valid_position(jump_row, jump_col) and state[jump_row, jump_col] == 0:\n",
    "                    from_pos = row * 8 + col\n",
    "                    to_pos = jump_row * 8 + jump_col\n",
    "                    action = from_pos * 64 + to_pos\n",
    "                    captures.append(action)\n",
    "\n",
    "        return captures\n",
    "\n",
    "    def action_to_coords(self, action):\n",
    "        \"\"\"Декодирует действие в координаты (from_row, from_col, to_row, to_col)\"\"\"\n",
    "        from_pos = action // 64\n",
    "        to_pos = action % 64\n",
    "        return (from_pos // 8, from_pos % 8, to_pos // 8, to_pos % 8)\n",
    "\n",
    "    def coords_to_action(self, from_row, from_col, to_row, to_col):\n",
    "        \"\"\"Кодирует координаты в действие\"\"\"\n",
    "        from_pos = from_row * 8 + from_col\n",
    "        to_pos = to_row * 8 + to_col\n",
    "        return from_pos * 64 + to_pos\n",
    "\n",
    "    def print_board(self, state):\n",
    "        \"\"\"Красивый вывод доски в консоль\"\"\"\n",
    "        symbols = {\n",
    "            0: '.',\n",
    "            1: 'w',   # Моя шашка\n",
    "            2: 'W',   # Моя дамка\n",
    "            -1: 'b',  # Шашка противника\n",
    "            -2: 'B'   # Дамка противника\n",
    "        }\n",
    "\n",
    "        print(\"  0 1 2 3 4 5 6 7\")\n",
    "        for row in range(self.row_count):\n",
    "            print(f\"{row} \", end=\"\")\n",
    "            for col in range(self.column_count):\n",
    "                print(symbols[state[row, col]] + \" \", end=\"\")\n",
    "            print()\n",
    "        print()"
   ],
   "id": "d8fb4cbd491364c8",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T19:33:08.647285Z",
     "start_time": "2025-12-15T19:29:55.759352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game = Checkers()\n",
    "player = -1\n",
    "device = torch.device(\"cpu\")\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 600,\n",
    "    'num_iterations': 10,\n",
    "    'batch_size': 64,\n",
    "    'num_selfplay_iterations': 400,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "model = ResNet(game, 12, 32, device=device)\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state).flatten()\n",
    "        print(\"val_movies\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}: \"))\n",
    "\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not val\")\n",
    "            continue\n",
    "    else:\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        mcts_probs, net_win_value = mcts.search(neutral_state)\n",
    "        print(\"expected win rate\", net_win_value)\n",
    "        valid_moves = game.get_valid_moves(neutral_state)\n",
    "        mcts_probs = mcts_probs * valid_moves  # Mask invalid moves to zero\n",
    "        action = np.argmax(mcts_probs)\n",
    "        action = game.flip_action(action)\n",
    "    state = game.get_next_state(state, action, player)\n",
    "\n",
    "    value, is_terminate = game.get_value_and_terminated(state, action)\n",
    "\n",
    "    if is_terminate:\n",
    "        if value == 1:\n",
    "            print(player, \"win\")\n",
    "        else:\n",
    "             print(player, \"lose\")\n",
    "        break\n",
    "\n",
    "    player = game.get_opponent(player)"
   ],
   "id": "6f17e81f0e296164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1  0 -1  0 -1  0 -1]\n",
      " [-1  0 -1  0 -1  0 -1  0]\n",
      " [ 0 -1  0 -1  0 -1  0 -1]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  0  1  0  1  0]\n",
      " [ 0  1  0  1  0  1  0  1]\n",
      " [ 1  0  1  0  1  0  1  0]]\n",
      "expected win rate 0.06525762379169464\n",
      "[[ 0 -1  0 -1  0 -1  0 -1]\n",
      " [-1  0 -1  0 -1  0 -1  0]\n",
      " [ 0 -1  0  0  0 -1  0 -1]\n",
      " [ 0  0  0  0 -1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  0  1  0  1  0]\n",
      " [ 0  1  0  1  0  1  0  1]\n",
      " [ 1  0  1  0  1  0  1  0]]\n",
      "val_movies [2593, 2721, 2723, 2851, 2853, 2981, 2983]\n",
      "[[ 0 -1  0 -1  0 -1  0 -1]\n",
      " [-1  0 -1  0 -1  0 -1  0]\n",
      " [ 0 -1  0  0  0 -1  0 -1]\n",
      " [ 0  0  0  0 -1  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  1  0]\n",
      " [ 0  1  0  1  0  1  0  1]\n",
      " [ 1  0  1  0  1  0  1  0]]\n",
      "expected win rate 0.08224310725927353\n",
      "[[ 0 -1  0 -1  0 -1  0 -1]\n",
      " [-1  0 -1  0 -1  0 -1  0]\n",
      " [ 0 -1  0  0  0 -1  0 -1]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 1  0 -1  0  1  0  1  0]\n",
      " [ 0  1  0  1  0  1  0  1]\n",
      " [ 1  0  1  0  1  0  1  0]]\n",
      "val_movies [3171, 3297]\n",
      "[[ 0 -1  0 -1  0 -1  0 -1]\n",
      " [-1  0 -1  0 -1  0 -1  0]\n",
      " [ 0 -1  0  0  0 -1  0 -1]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  1  0]\n",
      " [ 0  0  0  1  0  1  0  1]\n",
      " [ 1  0  1  0  1  0  1  0]]\n",
      "expected win rate 0.05829829350113869\n",
      "[[ 0 -1  0 -1  0 -1  0 -1]\n",
      " [-1  0 -1  0 -1  0 -1  0]\n",
      " [ 0  0  0  0  0 -1  0 -1]\n",
      " [ 0  0 -1  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  1  0]\n",
      " [ 0  0  0  1  0  1  0  1]\n",
      " [ 1  0  1  0  1  0  1  0]]\n",
      "val_movies [2257]\n",
      "[[ 0 -1  0 -1  0 -1  0 -1]\n",
      " [-1  0 -1  0 -1  0 -1  0]\n",
      " [ 0  1  0  0  0 -1  0 -1]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  1  0]\n",
      " [ 0  0  0  1  0  1  0  1]\n",
      " [ 1  0  1  0  1  0  1  0]]\n",
      "expected win rate 0.04941035807132721\n",
      "[[ 0 -1  0 -1  0 -1  0 -1]\n",
      " [ 0  0 -1  0 -1  0 -1  0]\n",
      " [ 0  0  0  0  0 -1  0 -1]\n",
      " [ 0  0 -1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  1  0]\n",
      " [ 0  0  0  1  0  1  0  1]\n",
      " [ 1  0  1  0  1  0  1  0]]\n",
      "val_movies [2593, 2851, 2853, 2981, 2983, 3306, 3633, 3761]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     23\u001B[39m valid_moves = game.get_valid_moves(state).flatten()\n\u001B[32m     24\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mval_movies\u001B[39m\u001B[33m\"\u001B[39m, [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(game.action_size) \u001B[38;5;28;01mif\u001B[39;00m valid_moves[i] == \u001B[32m1\u001B[39m])\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m action = \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mplayer\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m: \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m valid_moves[action] == \u001B[32m0\u001B[39m:\n\u001B[32m     28\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33maction not val\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/ipykernel/kernelbase.py:1396\u001B[39m, in \u001B[36mKernel.raw_input\u001B[39m\u001B[34m(self, prompt)\u001B[39m\n\u001B[32m   1394\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1395\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[32m-> \u001B[39m\u001B[32m1396\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1397\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1398\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_shell_context_var\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_shell_parent_ident\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1399\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1400\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1401\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/ipykernel/kernelbase.py:1441\u001B[39m, in \u001B[36mKernel._input_request\u001B[39m\u001B[34m(self, prompt, ident, parent, password)\u001B[39m\n\u001B[32m   1438\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1439\u001B[39m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[32m   1440\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mInterrupted by user\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1441\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1442\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1443\u001B[39m     \u001B[38;5;28mself\u001B[39m.log.warning(\u001B[33m\"\u001B[39m\u001B[33mInvalid Message:\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T18:30:44.211688Z",
     "start_time": "2025-12-15T18:30:44.209198Z"
    }
   },
   "cell_type": "code",
   "source": "mcts_probs[0].shape",
   "id": "a1fff40b05986095",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:38:06.757411Z",
     "start_time": "2025-12-15T15:38:06.754673Z"
    }
   },
   "cell_type": "code",
   "source": "сheckers.print_board(state)",
   "id": "53f53b5965ad329c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 1 2 3 4 5 6 7\n",
      "0 . w . w . w . w \n",
      "1 w . w . w . w . \n",
      "2 . w . w . w . w \n",
      "3 . . . . . . . . \n",
      "4 . . . . . . . . \n",
      "5 b . b . b . b . \n",
      "6 . b . b . b . b \n",
      "7 b . b . b . b . \n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T15:55:41.155858Z",
     "start_time": "2025-12-15T15:55:41.148859Z"
    }
   },
   "cell_type": "code",
   "source": "сheckers.action_size",
   "id": "a6e33a7c985755df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "261ef4db7fea0f74"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
