{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-15T13:36:02.725046Z",
     "start_time": "2025-12-15T13:36:01.806409Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from games.tictactoe import TicTacToe\n",
    "from games.connectfour import ConnectFour\n",
    "from models.mcts import MCTS, MCTSParallel\n",
    "from models.resnet import ResNet\n",
    "from models.deepzero import DeepZero, DeepZeroParallel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# tictactoe game",
   "id": "966d13a051eb6121"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a7b794537a1732c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:37:46.812284Z",
     "start_time": "2025-12-15T13:37:46.726857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game = TicTacToe()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = ResNet(game, 4, 32, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "player = 1\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 100,\n",
    "    'num_iterations': 3,\n",
    "    'num_parallel_games': 100,\n",
    "    'batch_size': 16,\n",
    "    'num_selfplay_iterations': 350,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "deepzero = DeepZeroParallel(model, optimizer, game, args)\n",
    "deepzero.learn()\n"
   ],
   "id": "83e6c74a1acb2f75",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     10\u001B[39m args = {\n\u001B[32m     11\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mC\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m2\u001B[39m,\n\u001B[32m     12\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mnum_search\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m100\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     20\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mdirichlet_alpha\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m0.3\u001B[39m\n\u001B[32m     21\u001B[39m }\n\u001B[32m     23\u001B[39m deepzero = DeepZeroParallel(model, optimizer, game, args)\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[43mdeepzero\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/deepzero.py:177\u001B[39m, in \u001B[36mDeepZeroParallel.learn\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    175\u001B[39m \u001B[38;5;28mself\u001B[39m.model.eval()\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m selfPlay_iteration \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;28mself\u001B[39m.args[\u001B[33m'\u001B[39m\u001B[33mnum_selfplay_iterations\u001B[39m\u001B[33m'\u001B[39m] // \u001B[38;5;28mself\u001B[39m.args[\u001B[33m'\u001B[39m\u001B[33mnum_parallel_games\u001B[39m\u001B[33m'\u001B[39m]):\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m     memory += \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mselfPlay\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[38;5;28mself\u001B[39m.model.train()\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;28mself\u001B[39m.args[\u001B[33m'\u001B[39m\u001B[33mnum_epochs\u001B[39m\u001B[33m'\u001B[39m]):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/deepzero.py:113\u001B[39m, in \u001B[36mDeepZeroParallel.selfPlay\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    110\u001B[39m states = np.stack([spg.state \u001B[38;5;28;01mfor\u001B[39;00m spg \u001B[38;5;129;01min\u001B[39;00m spGames])\n\u001B[32m    111\u001B[39m neutral_states = \u001B[38;5;28mself\u001B[39m.game.change_perspective(states, player)\n\u001B[32m--> \u001B[39m\u001B[32m113\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmcts\u001B[49m\u001B[43m.\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneutral_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspGames\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(spGames))[::-\u001B[32m1\u001B[39m]:\n\u001B[32m    116\u001B[39m     spg = spGames[i]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/mcts.py:145\u001B[39m, in \u001B[36mMCTSParallel.search\u001B[39m\u001B[34m(self, states, spGames)\u001B[39m\n\u001B[32m    142\u001B[39m node = spg.root\n\u001B[32m    144\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m node.is_fully_expanded():\n\u001B[32m--> \u001B[39m\u001B[32m145\u001B[39m     node = \u001B[43mnode\u001B[49m\u001B[43m.\u001B[49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    147\u001B[39m value, is_terminate = \u001B[38;5;28mself\u001B[39m.game.get_value_and_terminated(node.state, node.action_taken)\n\u001B[32m    148\u001B[39m value = \u001B[38;5;28mself\u001B[39m.game.get_opponent_value(value)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/mcts.py:28\u001B[39m, in \u001B[36mNode.select\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m child \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children:\n\u001B[32m     27\u001B[39m     ucb = \u001B[38;5;28mself\u001B[39m.get_ucb(child)\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mucb\u001B[49m\u001B[43m \u001B[49m\u001B[43m>\u001B[49m\u001B[43m \u001B[49m\u001B[43mbest_ucb\u001B[49m:\n\u001B[32m     29\u001B[39m         best_child = child\n\u001B[32m     30\u001B[39m         best_ucb = ucb\n",
      "\u001B[31mRuntimeError\u001B[39m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "game = TicTacToe()\n",
    "player = 1\n",
    "device = torch.device(\"cpu\")\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 100,\n",
    "    'num_iterations': 3,\n",
    "    'batch_size': 16,\n",
    "    'num_selfplay_iterations': 350,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "model = ResNet(game, 4, 32, device=device)\n",
    "model.load_state_dict(torch.load(\"weights/model_2.pt\", map_location=device))\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        print(\"val_movies\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}: \"))\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not val\")\n",
    "            continue\n",
    "    else:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        mcts_probs = mcts.search(neutral_state)\n",
    "        mcts_probs = mcts_probs * valid_moves  # Mask invalid moves to zero\n",
    "        action = np.argmax(mcts_probs)\n",
    "        # Optional: Add a check for no valid moves, though this should not occur in a proper game state\n",
    "        if valid_moves[action] == 0:\n",
    "            raise ValueError(\"No valid moves available; game state may be invalid.\")\n",
    "\n",
    "    state = game.get_next_state(state, action, player)\n",
    "    value, is_terminate = game.get_value_and_terminated(state, action)\n",
    "    if is_terminate:\n",
    "        if value == 1:\n",
    "            print(player, \"win\")\n",
    "        else:\n",
    "            print(player, \"lose\")\n",
    "        break\n",
    "    player = game.get_opponent(player)"
   ],
   "id": "2e7f7b9aa1788d1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "game = ConnectFour()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = ResNet(game, 9, 32, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "player = 1\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 600,\n",
    "    'num_iterations': 8,\n",
    "    'batch_size': 64,\n",
    "    'num_selfplay_iterations': 500,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "deepzero = DeepZero(model, optimizer, game, args)\n",
    "deepzero.learn()\n"
   ],
   "id": "269bc8b9c80750d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "game = ConnectFour()\n",
    "player = 1\n",
    "device = torch.device(\"cpu\")\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 600,\n",
    "    'num_iterations': 8,\n",
    "    'batch_size': 64,\n",
    "    'num_selfplay_iterations': 500,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "model = ResNet(game, 9, 32, device=device)\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        print(\"val_movies\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}: \"))\n",
    "\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not val\")\n",
    "            continue\n",
    "    else:\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        mcts_probs = mcts.search(neutral_state)\n",
    "        action = np.argmax(mcts_probs)\n",
    "\n",
    "    state = game.get_next_state(state, action, player)\n",
    "\n",
    "    value, is_terminate = game.get_value_and_terminated(state, action)\n",
    "\n",
    "    if is_terminate:\n",
    "        if value == 1:\n",
    "            print(player, \"win\")\n",
    "        else:\n",
    "             print(player, \"lose\")\n",
    "        break\n",
    "\n",
    "    player = game.get_opponent(player)"
   ],
   "id": "529975a467b87707",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    print(state)\n",
    "    if player == 1:\n",
    "        valid_moves = tictactoe.get_valid_moves(state)\n",
    "        neutral_state = tictactoe.change_perspective(state, player)\n",
    "        mcts_probs = mcts.search(neutral_state)\n",
    "        action = np.argmax(mcts_probs)\n",
    "\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not val\")\n",
    "            continue\n",
    "    else:\n",
    "        neutral_state = tictactoe.change_perspective(state, player)\n",
    "        mcts_probs = mcts.search(neutral_state)\n",
    "        action = np.argmax(mcts_probs)\n",
    "\n",
    "    state = tictactoe.get_next_state(state, action, player)\n",
    "\n",
    "    value, is_terminate = tictactoe.get_value_and_terminated(state, action)\n",
    "\n",
    "    if is_terminate:\n",
    "        if value == 1:\n",
    "            print(player, \"win\")\n",
    "        else:\n",
    "            print(player, \"lose\")\n",
    "        break\n",
    "\n",
    "    player = tictactoe.get_opponent(player)"
   ],
   "id": "fe0111dc8edff67b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "game.get_next_state(state, player)",
   "id": "d4ffdf1b33741ef4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d8fb4cbd491364c8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
