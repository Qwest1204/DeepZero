{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-15T22:20:08.217712Z",
     "start_time": "2025-12-15T22:20:07.308547Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from games.tictactoe import TicTacToe\n",
    "from games.connectfour import ConnectFour\n",
    "from games.checkers import Checkers\n",
    "from models.mcts import MCTS, MCTSParallel\n",
    "from models.resnet import ResNet\n",
    "from models.deepzero import DeepZero, DeepZeroParallel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "game = TicTacToe()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = ResNet(game, 4, 32, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "player = 1\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 100,\n",
    "    'num_iterations': 3,\n",
    "    'num_parallel_games': 100,\n",
    "    'batch_size': 16,\n",
    "    'num_selfplay_iterations': 350,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 1\n",
    "}\n",
    "\n",
    "deepzero = DeepZeroParallel(model, optimizer, game, args)\n",
    "deepzero.learn()\n"
   ],
   "id": "83e6c74a1acb2f75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "game = TicTacToe()\n",
    "player = -1\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 100,\n",
    "    'num_iterations': 3,\n",
    "    'num_parallel_games': 100,\n",
    "    'batch_size': 16,\n",
    "    'num_selfplay_iterations': 350,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "\n",
    "model = ResNet(game, 4, 32, device=device)\n",
    "model.load_state_dict(torch.load(\"weights/model_2_TicTacToe.pt\", map_location=device))\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        print(\"val_movies\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}: \"))\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not val\")\n",
    "            continue\n",
    "    else:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        mcts_probs, net_win_value = mcts.search(neutral_state)\n",
    "        print(\"expected win rate\", net_win_value)\n",
    "        mcts_probs = mcts_probs * valid_moves  # Mask invalid moves to zero\n",
    "        action = np.argmax(mcts_probs)\n",
    "        # Optional: Add a check for no valid moves, though this should not occur in a proper game state\n",
    "        if valid_moves[action] == 0:\n",
    "            raise ValueError(\"No valid moves available; game state may be invalid.\")\n",
    "\n",
    "    state = game.get_next_state(state, action, player)\n",
    "    value, is_terminate = game.get_value_and_terminated(state, action)\n",
    "    if is_terminate:\n",
    "        if value == 1:\n",
    "            print(player, \"win\")\n",
    "        else:\n",
    "            print(player, \"lose\")\n",
    "        break\n",
    "    player = game.get_opponent(player)"
   ],
   "id": "2e7f7b9aa1788d1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "game = ConnectFour()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = ResNet(game, 9, 64, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "player = 1\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 600,\n",
    "    'num_iterations': 8,\n",
    "    'batch_size': 64,\n",
    "    'num_selfplay_iterations': 500,\n",
    "    'num_parallel_games': 100,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "deepzero = DeepZeroParallel(model, optimizer, game, args)\n",
    "deepzero.learn()\n"
   ],
   "id": "269bc8b9c80750d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "game = ConnectFour()\n",
    "player = -1\n",
    "device = torch.device(\"cpu\")\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_search': 500,\n",
    "    'num_iterations': 10,\n",
    "    'batch_size': 64,\n",
    "    'num_selfplay_iterations': 500,\n",
    "    'num_epochs': 4,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "model = ResNet(game, 9, 128, device=device)\n",
    "model.load_state_dict(torch.load(\"weights/model_4_ConnectFour.pt\", map_location=device))\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        print(\"val_movies\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}: \"))\n",
    "\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not val\")\n",
    "            continue\n",
    "    else:\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        mcts_probs, net_win_value = mcts.search(neutral_state)\n",
    "        print(\"expected win rate\", net_win_value)\n",
    "        action = np.argmax(mcts_probs)\n",
    "\n",
    "    state = game.get_next_state(state, action, player)\n",
    "\n",
    "    value, is_terminate = game.get_value_and_terminated(state, action)\n",
    "\n",
    "    if is_terminate:\n",
    "        if value == 1:\n",
    "            print(player, \"win\")\n",
    "        else:\n",
    "             print(player, \"lose\")\n",
    "        break\n",
    "\n",
    "    player = game.get_opponent(player)"
   ],
   "id": "529975a467b87707",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T22:24:14.850547Z",
     "start_time": "2025-12-15T22:23:57.171110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game = Checkers()\n",
    "player = -1\n",
    "device = torch.device(\"cpu\")\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 400,\n",
    "    'num_iterations': 10,\n",
    "    'num_parallel_games': 200,\n",
    "    'batch_size': 128,\n",
    "    'num_selfPlay_iterations': 1000,\n",
    "    'num_epochs': 10,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "model = ResNet(game, 24, 256, device=device)\n",
    "model.load_state_dict(torch.load(\"weights/model_3_Checkers.pt\", map_location=device))\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    game.print_board(state)\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state).flatten()\n",
    "        print(\"val_movies\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}: \"))\n",
    "\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not val\")\n",
    "            continue\n",
    "    else:\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        mcts_probs, net_win_value = mcts.search(neutral_state)\n",
    "        print(\"expected win rate\", net_win_value)\n",
    "        valid_moves = game.get_valid_moves(neutral_state)\n",
    "        mcts_probs = mcts_probs * valid_moves  # Mask invalid moves to zero\n",
    "        action = np.argmax(mcts_probs)\n",
    "        action = game.flip_action(action)\n",
    "    state = game.get_next_state(state, action, player)\n",
    "\n",
    "    value, is_terminate = game.get_value_and_terminated(state, action)\n",
    "\n",
    "    if is_terminate:\n",
    "        if value == 1:\n",
    "            print(player, \"win\")\n",
    "        else:\n",
    "             print(player, \"lose\")\n",
    "        break\n",
    "\n",
    "    player = game.get_opponent(player)"
   ],
   "id": "6f17e81f0e296164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 1 2 3 4 5 6 7\n",
      "0 . b . b . b . b \n",
      "1 b . b . b . b . \n",
      "2 . b . b . b . b \n",
      "3 . . . . . . . . \n",
      "4 . . . . . . . . \n",
      "5 w . w . w . w . \n",
      "6 . w . w . w . w \n",
      "7 w . w . w . w . \n",
      "\n",
      "expected win rate_w 0.3734758198261261\n",
      "  0 1 2 3 4 5 6 7\n",
      "0 . b . b . b . b \n",
      "1 b . b . b . b . \n",
      "2 . b . b . b . . \n",
      "3 . . . . . . b . \n",
      "4 . . . . . . . . \n",
      "5 w . w . w . w . \n",
      "6 . w . w . w . w \n",
      "7 w . w . w . w . \n",
      "\n",
      "expected win rate_p 0.3088635206222534\n",
      "  0 1 2 3 4 5 6 7\n",
      "0 . b . b . b . b \n",
      "1 b . b . b . b . \n",
      "2 . b . b . b . . \n",
      "3 . . . . . . b . \n",
      "4 . . . . . . . . \n",
      "5 w . w . w . w . \n",
      "6 . w . w . w . w \n",
      "7 w . w . w . w . \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 36\u001B[39m\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     35\u001B[39m     neutral_state = game.change_perspective(state, player)\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m     mcts_probs, net_win_value = \u001B[43mmcts_w\u001B[49m\u001B[43m.\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneutral_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     37\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mexpected win rate_w\u001B[39m\u001B[33m\"\u001B[39m, net_win_value)\n\u001B[32m     38\u001B[39m     valid_moves = game.get_valid_moves(neutral_state)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/mcts.py:163\u001B[39m, in \u001B[36mMCTS.search\u001B[39m\u001B[34m(self, state)\u001B[39m\n\u001B[32m    160\u001B[39m value = \u001B[38;5;28mself\u001B[39m.game.get_opponent_value(value)\n\u001B[32m    162\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_terminal:\n\u001B[32m--> \u001B[39m\u001B[32m163\u001B[39m     policy, value = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    164\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgame\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_encoded_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    165\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    166\u001B[39m     policy = torch.softmax(policy, axis=\u001B[32m1\u001B[39m).squeeze(\u001B[32m0\u001B[39m).cpu().numpy()\n\u001B[32m    167\u001B[39m     valid_moves = \u001B[38;5;28mself\u001B[39m.game.get_valid_moves(node.state)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/resnet.py:43\u001B[39m, in \u001B[36mResNet.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     41\u001B[39m x = \u001B[38;5;28mself\u001B[39m.startBlock(x)\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m resBlock \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.backBone:\n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m     x = \u001B[43mresBlock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     44\u001B[39m policy = \u001B[38;5;28mself\u001B[39m.policyHead(x)\n\u001B[32m     45\u001B[39m value = \u001B[38;5;28mself\u001B[39m.valueHead(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/resnet.py:59\u001B[39m, in \u001B[36mResBlock.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     57\u001B[39m residual = x\n\u001B[32m     58\u001B[39m x = F.relu(\u001B[38;5;28mself\u001B[39m.bn1(\u001B[38;5;28mself\u001B[39m.conv1(x)))\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m x = \u001B[38;5;28mself\u001B[39m.bn2(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     60\u001B[39m x += residual\n\u001B[32m     61\u001B[39m x = F.relu(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/nn/modules/conv.py:548\u001B[39m, in \u001B[36mConv2d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    547\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m548\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/nn/modules/conv.py:543\u001B[39m, in \u001B[36mConv2d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    531\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m\"\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    532\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(\n\u001B[32m    533\u001B[39m         F.pad(\n\u001B[32m    534\u001B[39m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode\n\u001B[32m   (...)\u001B[39m\u001B[32m    541\u001B[39m         \u001B[38;5;28mself\u001B[39m.groups,\n\u001B[32m    542\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m543\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    544\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\n\u001B[32m    545\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T22:34:33.551103Z",
     "start_time": "2025-12-15T22:33:51.989921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game = Checkers()\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Базовые параметры MCTS\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 800,\n",
    "    'num_iterations': 10,\n",
    "    'num_parallel_games': 200,\n",
    "    'batch_size': 128,\n",
    "    'num_selfPlay_iterations': 1000,\n",
    "    'num_epochs': 10,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "# Для матча лучше отключить шум Дирихле и сделать temperature=1 (или <1)\n",
    "eval_args = args.copy()\n",
    "eval_args['dirichlet_epsilon'] = 0.0\n",
    "eval_args['temperature'] = 1.0\n",
    "\n",
    "# === МОДЕЛЬ / АЛГОРИТМ ДЛЯ БЕЛЫХ (player = 1) ===\n",
    "model_white = ResNet(game, 24, 256, device=device)\n",
    "model_white.load_state_dict(torch.load(\"weights/model_3_Checkers.pt\", map_location=device))\n",
    "model_white.eval()\n",
    "mcts_white = MCTS(game, eval_args, model_white)\n",
    "\n",
    "# === МОДЕЛЬ / АЛГОРИТМ ДЛЯ ЧЁРНЫХ (player = -1) ===\n",
    "model_black = ResNet(game, 24, 256, device=device)\n",
    "model_black.load_state_dict(torch.load(\"weights/model_3_Checkers.pt\", map_location=device))\n",
    "model_black.eval()\n",
    "mcts_black = MCTS(game, eval_args, model_black)\n",
    "\n",
    "# Если у вас один и тот же файл весов для обоих:\n",
    "# model_white.load_state_dict(torch.load(\"weights/model_3_Checkers.pt\", map_location=device))\n",
    "# model_black.load_state_dict(torch.load(\"weights/model_3_Checkers.pt\", map_location=device))\n",
    "\n",
    "state = game.get_initial_state()\n",
    "player = 1  # белые начинают\n",
    "\n",
    "while True:\n",
    "    game.print_board(state)\n",
    "    print(f\"Ход игрока {player} ({'белые' if player == 1 else 'чёрные'})\")\n",
    "\n",
    "    # Выбираем, каким MCTS пользоваться\n",
    "    if player == 1:\n",
    "        mcts_current = mcts_white\n",
    "    else:\n",
    "        mcts_current = mcts_black\n",
    "\n",
    "    # Переводим позицию в нейтральную перспективу текущего игрока\n",
    "    neutral_state = game.change_perspective(state, player)\n",
    "\n",
    "    # --- Вариант 1: если ваш MCTS.search возвращает только политику ---\n",
    "    # mcts_probs = mcts_current.search(neutral_state)\n",
    "\n",
    "    # --- Вариант 2: если MCTS.search возвращает (политика, value) ---\n",
    "    mcts_probs, net_win_value = mcts_current.search(neutral_state)\n",
    "    print(\"Оценка шансов на победу (с точки зрения текущего игрока):\", net_win_value)\n",
    "\n",
    "    # Маска допустимых ходов\n",
    "    valid_moves = game.get_valid_moves(neutral_state)\n",
    "    mcts_probs = mcts_probs * valid_moves  # обнуляем запрещённые ходы\n",
    "\n",
    "    if mcts_probs.sum() == 0:\n",
    "        # MCTS не предложил ходов — делаем fallback: выбираем любой допустимый\n",
    "        valid_indices = np.where(valid_moves == 1)[0]\n",
    "        if len(valid_indices) == 0:\n",
    "            # У текущего игрока реально нет ходов — партия окончена\n",
    "            value, is_terminate = game.get_value_and_terminated(neutral_state, None)\n",
    "            if value == 1:\n",
    "                print(f\"Игрок {player} выиграл (нет ходов у противника)!\")\n",
    "            else:\n",
    "                print(f\"Игрок {player} не может ходить — проигрыш или ничья.\")\n",
    "            break\n",
    "        action_neutral = np.random.choice(valid_indices)\n",
    "    else:\n",
    "        # Жадный выбор лучшего хода\n",
    "        action_neutral = np.argmax(mcts_probs)\n",
    "\n",
    "    # Для чёрных нужно перевести ход обратно в глобальные координаты\n",
    "    if player == -1:\n",
    "        action = game.flip_action(action_neutral)\n",
    "    else:\n",
    "        action = action_neutral\n",
    "\n",
    "    # Применяем ход к \"реальному\" состоянию\n",
    "    state = game.get_next_state(state, action, player)\n",
    "\n",
    "    # Проверяем окончание игры\n",
    "    value, is_terminate = game.get_value_and_terminated(state, action)\n",
    "    if is_terminate:\n",
    "        game.print_board(state)\n",
    "        if value == 1:\n",
    "            print(f\"Игрок {player} ({'белые' if player == 1 else 'чёрные'}) выиграл!\")\n",
    "        else:\n",
    "            print(f\"Игрок {player} ({'белые' if player == 1 else 'чёрные'}) проиграл!\")\n",
    "        break\n",
    "\n",
    "    # Меняем игрока\n",
    "    player = game.get_opponent(player)"
   ],
   "id": "a1fff40b05986095",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 1 2 3 4 5 6 7\n",
      "0 . b . b . b . b \n",
      "1 b . b . b . b . \n",
      "2 . b . b . b . b \n",
      "3 . . . . . . . . \n",
      "4 . . . . . . . . \n",
      "5 w . w . w . w . \n",
      "6 . w . w . w . w \n",
      "7 w . w . w . w . \n",
      "\n",
      "Ход игрока 1 (белые)\n",
      "Оценка шансов на победу (с точки зрения текущего игрока): 0.3537505269050598\n",
      "  0 1 2 3 4 5 6 7\n",
      "0 . b . b . b . b \n",
      "1 b . b . b . b . \n",
      "2 . b . b . b . b \n",
      "3 . . . . . . . . \n",
      "4 . . . . . w . . \n",
      "5 w . w . . . w . \n",
      "6 . w . w . w . w \n",
      "7 w . w . w . w . \n",
      "\n",
      "Ход игрока -1 (чёрные)\n",
      "Оценка шансов на победу (с точки зрения текущего игрока): 0.39288923144340515\n",
      "  0 1 2 3 4 5 6 7\n",
      "0 . b . b . b . b \n",
      "1 b . b . b . b . \n",
      "2 . b . b . b . . \n",
      "3 . . . . . . b . \n",
      "4 . . . . . w . . \n",
      "5 w . w . . . w . \n",
      "6 . w . w . w . w \n",
      "7 w . w . w . w . \n",
      "\n",
      "Ход игрока 1 (белые)\n",
      "Оценка шансов на победу (с точки зрения текущего игрока): 0.34579038619995117\n",
      "  0 1 2 3 4 5 6 7\n",
      "0 . b . b . b . b \n",
      "1 b . b . b . b . \n",
      "2 . b . b . b . w \n",
      "3 . . . . . . . . \n",
      "4 . . . . . . . . \n",
      "5 w . w . . . w . \n",
      "6 . w . w . w . w \n",
      "7 w . w . w . w . \n",
      "\n",
      "Ход игрока -1 (чёрные)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 59\u001B[39m\n\u001B[32m     53\u001B[39m neutral_state = game.change_perspective(state, player)\n\u001B[32m     55\u001B[39m \u001B[38;5;66;03m# --- Вариант 1: если ваш MCTS.search возвращает только политику ---\u001B[39;00m\n\u001B[32m     56\u001B[39m \u001B[38;5;66;03m# mcts_probs = mcts_current.search(neutral_state)\u001B[39;00m\n\u001B[32m     57\u001B[39m \n\u001B[32m     58\u001B[39m \u001B[38;5;66;03m# --- Вариант 2: если MCTS.search возвращает (политика, value) ---\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m mcts_probs, net_win_value = \u001B[43mmcts_current\u001B[49m\u001B[43m.\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneutral_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mОценка шансов на победу (с точки зрения текущего игрока):\u001B[39m\u001B[33m\"\u001B[39m, net_win_value)\n\u001B[32m     62\u001B[39m \u001B[38;5;66;03m# Маска допустимых ходов\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/.venv/lib/python3.14/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/mcts.py:181\u001B[39m, in \u001B[36mMCTS.search\u001B[39m\u001B[34m(self, state)\u001B[39m\n\u001B[32m    178\u001B[39m         value = value.item()\n\u001B[32m    179\u001B[39m         winrate = value\n\u001B[32m--> \u001B[39m\u001B[32m181\u001B[39m         \u001B[43mnode\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexpand\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpolicy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    183\u001B[39m     node.backpropagate(value)\n\u001B[32m    185\u001B[39m action_probs = np.zeros(\u001B[38;5;28mself\u001B[39m.game.action_size)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DeepZero/models/mcts.py:96\u001B[39m, in \u001B[36mNode.expand\u001B[39m\u001B[34m(self, policy)\u001B[39m\n\u001B[32m     94\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mexpand\u001B[39m(\u001B[38;5;28mself\u001B[39m, policy):\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m action, prob \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(policy):\n\u001B[32m---> \u001B[39m\u001B[32m96\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m prob > \u001B[32m0\u001B[39m:\n\u001B[32m     97\u001B[39m             child_state = \u001B[38;5;28mself\u001B[39m.state.copy()\n\u001B[32m     98\u001B[39m             child_state = \u001B[38;5;28mself\u001B[39m.game.get_next_state(child_state, action, \u001B[32m1\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e33104503a2b767e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
